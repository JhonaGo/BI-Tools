{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iChlSVKhjTYx54KausMGlnqolAm7TLh6",
      "authorship_tag": "ABX9TyNg6ktGtkq+9FhCpMO66C2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JhonaGo/BI-Tools/blob/main/Catalogue_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlnrFKOonWXl"
      },
      "outputs": [],
      "source": [
        "# Need to import to use date time\n",
        "from datetime import datetime, date\n",
        "\n",
        "# need to import for working with pandas\n",
        "import pandas as pd\n",
        "\n",
        "# need to import to use pyspark\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# need to import for session creation\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# creating the session\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creacion de catalogos"
      ],
      "metadata": {
        "id": "37I1HUiMoYyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pyspark dataframe\n",
        "rdd = spark.sparkContext.parallelize([\n",
        "    (1, 4., 'GFG1', date(2000, 8, 1), datetime(2000, 8, 1, 12, 0)),\n",
        "    (2, 8., 'GFG2', date(2000, 6, 2), datetime(2000, 6, 2, 12, 0)),\n",
        "    (3, 5., 'GFG3', date(2000, 5, 3), datetime(2000, 5, 3, 12, 0))\n",
        "])\n",
        "df = spark.createDataFrame(rdd, schema=['a', 'b', 'c', 'd', 'e'])\n",
        "df\n",
        "\n",
        "# show table\n",
        "df.show()\n",
        "\n",
        "# show schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3hLgxMuoakw",
        "outputId": "a82d5925-ba6d-457f-cf0e-29baaa556606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+----+----------+-------------------+\n",
            "|  a|  b|   c|         d|                  e|\n",
            "+---+---+----+----------+-------------------+\n",
            "|  1|4.0|GFG1|2000-08-01|2000-08-01 12:00:00|\n",
            "|  2|8.0|GFG2|2000-06-02|2000-06-02 12:00:00|\n",
            "|  3|5.0|GFG3|2000-05-03|2000-05-03 12:00:00|\n",
            "+---+---+----+----------+-------------------+\n",
            "\n",
            "root\n",
            " |-- a: long (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- c: string (nullable = true)\n",
            " |-- d: date (nullable = true)\n",
            " |-- e: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considerar que el catalogo inicial esta en formato de excel. Para ello hay que seguir una serie de pasos para poder convertilo en un esquema Spark."
      ],
      "metadata": {
        "id": "kmzojLRjrjfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import pandas as ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHdkbV7BtU1i",
        "outputId": "912c7983-a177-4d3a-be7f-2120dbedfb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pd.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s45ywiBmWBzK",
        "outputId": "dee16fd7-e02b-4541-9904-427689b8668b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2245 entries, 0 to 2244\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   key              2244 non-null   object\n",
            " 1   Site             2245 non-null   object\n",
            " 2   Holding          2245 non-null   object\n",
            " 3   identificador    2132 non-null   object\n",
            " 4   descripcion      2245 non-null   object\n",
            " 5   CODIGO           2006 non-null   object\n",
            " 6   codigo_anterior  53 non-null     object\n",
            " 7   EAN              671 non-null    object\n",
            " 8   Factor_Caja      2202 non-null   object\n",
            "dtypes: object(9)\n",
            "memory usage: 158.0+ KB\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import DoubleType, LongType, StructField, StructType, StringType\n",
        "\n",
        "# Read the Excel file into a Pandas DataFrame\n",
        "df_pd = pd.read_excel('/content/drive/Shareddrives/Catalogos_SO/Prod_Holding.xlsx')\n",
        "\n",
        "# Define the desired schema explicitly, accommodating potential mixed types\n",
        "schema = StructType([\n",
        "    StructField(\"Site\", StringType(), True),\n",
        "    StructField(\"Holding\", StringType(), True),\n",
        "    StructField(\"identificador\", StringType(), True),\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "# Convert the Pandas DataFrame to PySpark DataFrame using the defined schema\n",
        "df_spark = spark.createDataFrame(df_pd, schema=schema)\n",
        "\n",
        "df_spark.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGp27uopsZw9",
        "outputId": "2d24c3aa-6f8e-4f64-db78-7b9c19d0b8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+-------------+\n",
            "|                Site|Holding|identificador|\n",
            "+--------------------+-------+-------------+\n",
            "|1010BIG ROLL 4/40...|    MTY|        ABEJA|\n",
            "|1011BIG ROLL 6/55...|    MTY|        ABEJA|\n",
            "|3114COMBO BIG ROL...|    MTY|        ABEJA|\n",
            "|1019ELITE COLOR 4...|    MTY|        ABEJA|\n",
            "|2243ELITE GOLD 4/...|    MTY|        ABEJA|\n",
            "|2985ELITE MASCARI...|    MTY|        ABEJA|\n",
            "|3107ELITE SERVILL...|    MTY|        ABEJA|\n",
            "|3107ELITE SERVILL...|    MTY|        ABEJA|\n",
            "|1221ELITE SERVITO...|    MTY|        ABEJA|\n",
            "|1021PREMIER 4/400...|    MTY|        ABEJA|\n",
            "|2887PREMIER 4/600...|    MTY|        ABEJA|\n",
            "|3271PREMIER RENDI...|    MTY|        ABEJA|\n",
            "|3271PREMIER RENDI...|    MTY|        ABEJA|\n",
            "|1226PREMIER SERVI...|    MTY|        ABEJA|\n",
            "|1234PREMIER SERVI...|    MTY|        ABEJA|\n",
            "|1235PREMIER SERVI...|    MTY|        ABEJA|\n",
            "|3488ELITE SERVILL...|    MTY|        ABEJA|\n",
            "|CCG006ZZZ COTIDIA...|    MTY|        CAGSA|\n",
            "|CCME06ZZZ COTIDIA...|    MTY|        CAGSA|\n",
            "|HBR008HIG BIG ROL...|    MTY|        CAGSA|\n",
            "+--------------------+-------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}